{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_tutorial.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"c2cFbZW9ohTl","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2vH3mNjpEPw","colab_type":"text"},"source":["## Hướng dẫn sử dụng PyTorch\n","### PyTorch là gì?\n","Pytorch là thư viện deep learning có thể chạy trên GPU. Pytorch tương tự như Numpy và hoàn toàn có thể thay thế Numpy."]},{"cell_type":"code","metadata":{"id":"xDnSDN4XqOzQ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","# kiểm tra phiên bản của pytorch >= 1.0\n","print(\"torch version:\", torch.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"llk-pOYMDlB9","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nLNsvtrrqYxN","colab_type":"text"},"source":["Cách khởi tạo một tensor trong Pytorch. Các hàm trong Pytorch tương tự như Numpy"]},{"cell_type":"code","metadata":{"id":"HKaCKjCHp2WX","colab_type":"code","colab":{}},"source":["print('\\nCreate a zero ndarray in NumPy:')\n","zero_np = np.zeros([2, 3])\n","print(zero_np)\n","print('\\nCreate a zero tensor in PyTorch:')\n","zero_pt = torch.zeros([2,3])\n","print(zero_pt)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMOmCMKKzg1g","colab_type":"text"},"source":["Truy xuất phần tử của tensor theo index\n","\n"]},{"cell_type":"code","metadata":{"id":"4c5Dg7Y5zuJA","colab_type":"code","colab":{}},"source":["print(\"numpy: zero_np[0,1]: {}\\t(type: {})\".format(str(zero_np[0,1]), type(zero_np[0,1])))\n","print(\"torch: zero_pt[0,1]: {}\\t(type: {} / shape: {})\".format(str(zero_pt[0,1]), type(zero_pt[0,1]), zero_pt[0,1].shape))\n","# Use \"item()\" to get a Python number from a single-valued tensor.\n","print(\"       zero_pt[0,1].item(): {}\\t(type: {})\".format(zero_pt[0,1].item(), type(zero_pt[0,1].item())))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMB8fdiJFuBh","colab_type":"code","colab":{}},"source":["print(zero_pt.size())\n","print(zero_pt.type())\n","print(zero_pt[0,1].item())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rwwjdz0tz8cm","colab_type":"text"},"source":["Chuyển đổi từ Numpy sang Pytorch và ngược lại"]},{"cell_type":"code","metadata":{"id":"h8riFsiA0Biz","colab_type":"code","colab":{}},"source":["print('Turn a ndarray into a tensor with \"torch.tensor()\":')\n","zero_pt_from_np = torch.tensor(zero_np)\n","print(zero_pt_from_np)\n","print('or \"torch.from_numpy():\"')\n","zero_pt_from_np = torch.from_numpy(zero_np)\n","print(zero_pt_from_np)\n","\n","print('\\nTurn a tensor into ndarray with \".numpy()\":')\n","zero_np_from_pt = zero_pt.numpy()\n","print(zero_np_from_pt)\n","print(type(zero_np_from_pt))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvJ20AYkG3XH","colab_type":"code","colab":{}},"source":["a = torch.from_numpy(np.zeros([1,2]))\n","b = torch.zeros([1,2])\n","b+a"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvHRaxcc0aBf","colab_type":"text"},"source":["Chuyển một tensor lên GPU và ngược lại"]},{"cell_type":"code","metadata":{"id":"8nFjY3alH7LE","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7gvYV3o0CbX","colab_type":"code","colab":{}},"source":["t = torch.randn(2)\n","print(\"Initial device:\\t'{}'\".format(t.device))\n","t = t.to('cuda:0')\n","print(\"Move to gpu:\\t'{}'\".format(t.device))\n","t = t.to('cpu')\n","print(\"Back to cpu:\\t'{}'\".format(t.device))\n","t.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SeWwuvgdm93a","colab_type":"text"},"source":["Cơ chế Autograd của Pytorch"]},{"cell_type":"code","metadata":{"id":"mZBvWWufm8W9","colab_type":"code","colab":{}},"source":["x = torch.randn(5, 5)  # requires_grad=False by default\n","y = torch.randn(5, 5)  # requires_grad=False by default\n","z = torch.randn((5, 5), requires_grad=True)\n","a = x + y\n","print(a.requires_grad)\n","b = a + z\n","print(b.requires_grad)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDTmhdI-xEy2","colab_type":"text"},"source":["Tính đạo hàm $\\frac{dc}{dx}$"]},{"cell_type":"code","metadata":{"id":"YDfhzBnopPq9","colab_type":"code","colab":{}},"source":["x = torch.tensor([1.0])\n","y = torch.tensor([2.0])\n","z = torch.tensor([3.0])\n","x.requires_grad_()\n","c = x * y + z\n","print(c)\n","print(x.grad)\n","c.backward()\n","print(x)\n","print(x.grad)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWLlJ7zfpfA2","colab_type":"text"},"source":["Gán `requires_grad=False` có tác dụng khi dùng một mô hình pretrain (ví dụ VGG, Resnet, ...) có sẵn làm mạng nền cho một mô hình khác (ví dụ mô hình mạng phát hiện SSD). Khi đó mạng nền sẽ được \"đóng băng\" và sẽ không được cập nhật trọng số, trong khi đó các phần còn lại của mạng sẽ được cập nhật trọng số bình thường"]},{"cell_type":"code","metadata":{"id":"6LEfUu2vrNPg","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.models import resnet18"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4BbiWObrGVO","colab_type":"code","colab":{}},"source":["model = resnet18(pretrained=True)\n","for param in model.parameters():\n","    param.requires_grad = False\n","# Replace the last fully-connected layer\n","# Parameters of newly constructed modules have requires_grad=True by default\n","model.fc = nn.Linear(512, 100)\n","\n","# Optimize only the classifier\n","optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNxOqt9npR1w","colab_type":"text"},"source":["Huấn luyện mạng phân loại MNIST\n","=====\n","## Các bước để huấn luyện một mạng:\n"," - Chuẩn bị dữ liệu\n"," - Tạo mạng\n"," - Chọn bộ optimizer\n"," - Huấn luyện mô hình\n"," - Đánh giá kết quả"]},{"cell_type":"code","metadata":{"id":"QVZTuJ8Uph-h","colab_type":"code","colab":{}},"source":["import torch.nn as nn            # containing various building blocks for your neural networks\n","import torch.optim as optim      # implementing various optimization algorithms\n","import torch.nn.functional as F  # a lower level (compared to torch.nn) interface\n","\n","# torchvision: popular datasets, model architectures, and common image transformations for computer vision.\n","import torchvision\n","# transforms: transformations useful for image processing\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","import glob\n","import os.path as osp\n","import numpy as np\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzgAqIawq-bi","colab_type":"text"},"source":["## 1. Chuẩn bị dữ liệu\n","Chạy các câu lệnh sau để tải tập mnist:\n","\n","`wget https://github.com/myleott/mnist_png/blob/master/mnist_png.tar.gz?raw=true -O mnist_png.tar.gz`\n","\n","`tar -xzf mnist_png.tar.gz`"]},{"cell_type":"code","metadata":{"id":"KK7RYnwOrYsU","colab_type":"code","colab":{}},"source":["!wget https://github.com/myleott/mnist_png/blob/master/mnist_png.tar.gz?raw=true -O mnist_png.tar.gz\n","!tar -xzf mnist_png.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KYr6vK8O4HVg","colab_type":"text"},"source":["Trong gói torchvision có hiện thực sẵn một vài [dataset](https://pytorch.org/docs/stable/torchvision/datasets.html)"]},{"cell_type":"code","metadata":{"id":"NDbCl91Y75iE","colab_type":"code","colab":{}},"source":["trainset = torchvision.datasets.MNIST('/content', train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n","testset = torchvision.datasets.MNIST('/content', train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c79ceAkH415k","colab_type":"code","colab":{}},"source":["trainset = torchvision.datasets.CIFAR10('/content', train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n","testset = torchvision.datasets.CIFAR10('/content', train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHjP5jO87ISW","colab_type":"code","colab":{}},"source":["trainset = torchvision.datasets.CIFAR100('/content', train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n","testset = torchvision.datasets.CIFAR100('/content', train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9vSSzJbrZte","colab_type":"code","colab":{}},"source":["class MNIST(Dataset):\n","    \"\"\"\n","    A customized data loader for MNIST.\n","    \"\"\"\n","    def __init__(self,\n","                 root,\n","                 transform=None,\n","                 preload=False):\n","        \"\"\" Intialize the MNIST dataset\n","        \n","        Args:\n","            - root: root directory of the dataset\n","            - tranform: a custom tranform function\n","            - preload: if preload the dataset into memory\n","        \"\"\"\n","        self.images = None\n","        self.labels = None\n","        self.filenames = []\n","        self.root = root\n","        self.transform = transform\n","\n","        # read filenames\n","        for i in range(10):\n","            filenames = glob.glob(osp.join(root, str(i), '*.png'))\n","            for fn in filenames:\n","                self.filenames.append((fn, i)) # (filename, label) pair\n","                \n","        # if preload dataset into memory\n","        if preload:\n","            self._preload()\n","            \n","        self.len = len(self.filenames)\n","                              \n","    def _preload(self):\n","        \"\"\"\n","        Preload dataset to memory\n","        \"\"\"\n","        self.labels = []\n","        self.images = []\n","        for image_fn, label in self.filenames:            \n","            # load images\n","            image = cv2.imread(image_fn)\n","            self.images.append(image.copy())\n","            self.labels.append(label)\n","\n","    # probably the most important to customize.\n","    def __getitem__(self, index):\n","        \"\"\" Get a sample from the dataset\n","        \"\"\"\n","        if self.images is not None:\n","            # If dataset is preloaded\n","            image = self.images[index]\n","            label = self.labels[index]\n","        else:\n","            # If on-demand data loading\n","            image_fn, label = self.filenames[index]\n","            image = cv2.imread(image_fn)\n","            \n","        # May use transform function to transform samples\n","        # e.g., random crop, whitening\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        # return image and label\n","        return image, label\n","\n","    def __len__(self):\n","        \"\"\"\n","        Total number of samples in the dataset\n","        \"\"\"\n","        return self.len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"spU1KZGm6OIZ","colab_type":"text"},"source":["Sử dụng dataset tự tạo"]},{"cell_type":"code","metadata":{"id":"Z8TzT5ea6RjE","colab_type":"code","colab":{}},"source":["# Create the MNIST dataset. \n","# transforms.ToTensor() automatically converts PIL images to\n","# torch tensors with range [0, 1]\n","trainset = MNIST(\n","    root='mnist_png/training',\n","    preload=True, transform=transforms.ToTensor(),\n",")\n","\n","# Load the testset\n","testset = MNIST(\n","    root='mnist_png/testing',\n","    preload=True, transform=transforms.ToTensor(),\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UY_DqGaH1yd3","colab_type":"text"},"source":["Dữ liệu trước khi được đưa vào huấn luyện có thể trải qua một vài phép biến đổi. Đó được gọi là làm giàu dữ liệu. Một số hàm biến đổi tham khảo [link](https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-pil-image)"]},{"cell_type":"code","metadata":{"id":"AAFiaafnriFE","colab_type":"code","colab":{}},"source":["# Use the torch dataloader to iterate through the dataset\n","# We want the dataset to be shuffled during training.\n","trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n","\n","# Use the torch dataloader to iterate through the dataset\n","testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rBfiYAM6uQA","colab_type":"code","colab":{}},"source":["print(len(trainset)) # len = 60000\n","print(len(testset))  # len = 10000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vdRMMVN66z9N","colab_type":"text"},"source":["### Hiển thị dataset"]},{"cell_type":"code","metadata":{"id":"05IDieMT6zJ8","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","# functions to show an image\n","def imshow(img):\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","# get some random training images\n","dataiter = iter(trainset_loader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join('%5s' % labels[j] for j in range(16)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykFNVFOc6-qi","colab_type":"code","colab":{}},"source":["# Use GPU if available, otherwise stick with cpu\n","use_cuda = torch.cuda.is_available()\n","torch.manual_seed(123)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ZWtHzZm7Ea9","colab_type":"text"},"source":["## Tạo mạng"]},{"cell_type":"code","metadata":{"id":"E6Vrg20f7Iwq","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        # Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0,\n","        #        dilation=1, groups=1, bias=True, padding_mode='zeros')\n","        # NCHW\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        \n","        # Linear(in_features, out_features, bias=True)\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","        \n","        # MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n","        self.max_pool = nn.MaxPool2d(2)\n","        # ReLU(inplace=False)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        # Note: the following two ways for max pooling / relu are equivalent.\n","        # 1) with torch.nn.functional:\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        # 2) with torch.nn:\n","        x = self.relu(self.max_pool(self.conv2_drop(self.conv2(x))))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pGlLqSPo7L7D","colab_type":"text"},"source":["### Huấn luyện mạng"]},{"cell_type":"code","metadata":{"id":"pJpguPk87OBY","colab_type":"code","colab":{}},"source":["from time import time\n","def train(epoch, log_interval=100):\n","    model.train()  # set training mode\n","    iteration = 0\n","    for ep in range(epoch):\n","        start = time()\n","        for batch_idx, (data, target) in enumerate(trainset_loader):\n","            # bring data to the computing device, e.g. GPU\n","            data, target = data.to(device), target.to(device)\n","\n","            # forward pass\n","            output = model(data)\n","            # compute loss: negative log-likelihood\n","            loss = F.nll_loss(output, target)\n","            \n","            # backward pass\n","            # clear the gradients of all tensors being optimized.\n","            optimizer.zero_grad()\n","            # accumulate (i.e. add) the gradients from this forward pass\n","            loss.backward()\n","            # performs a single optimization step (parameter update)\n","            optimizer.step()\n","            \n","            if iteration % log_interval == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n","                    100. * batch_idx / len(trainset_loader), loss.item()))\n","            iteration += 1\n","            \n","        end = time()\n","        print('{:.2f}s'.format(end-start))\n","        test() # evaluate at the end of epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XiprQ7cU7V7E","colab_type":"code","colab":{}},"source":["def test():\n","    model.eval()  # set evaluation mode\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in testset_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(testset_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(testset_loader.dataset),\n","        100. * correct / len(testset_loader.dataset)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySwJZ7QE7Zvt","colab_type":"code","colab":{}},"source":["train(5)  # train 5 epochs should get you to about 97% accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4zt-8XoA7fC1","colab_type":"text"},"source":["### Lưu mô hình đã train"]},{"cell_type":"code","metadata":{"id":"j9sTk4xR7hG4","colab_type":"code","colab":{}},"source":["def save_checkpoint(checkpoint_path, model, optimizer):\n","    # state_dict: a Python dictionary object that:\n","    # - for a model, maps each layer to its parameter tensor;\n","    # - for an optimizer, contains info about the optimizer’s states and hyperparameters used.\n","    state = {\n","        'state_dict': model.state_dict(),\n","        'optimizer' : optimizer.state_dict()}\n","    torch.save(state, checkpoint_path)\n","    print('model saved to %s' % checkpoint_path)\n","    \n","def load_checkpoint(checkpoint_path, model, optimizer):\n","    state = torch.load(checkpoint_path)\n","    model.load_state_dict(state['state_dict'])\n","    optimizer.load_state_dict(state['optimizer'])\n","    print('model loaded from %s' % checkpoint_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KL2sEDDB7oGb","colab_type":"code","colab":{}},"source":["# create a brand new model\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","# Testing -- you should get a pretty poor performance since the model hasn't learned anything yet.\n","test()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6G14d7N87whk","colab_type":"text"},"source":["Lưu mô hình"]},{"cell_type":"code","metadata":{"id":"eBnIvU4y7zco","colab_type":"code","colab":{}},"source":["def train_save(epoch, save_interval, log_interval=100):\n","    model.train()  # set training mode\n","    iteration = 0\n","    for ep in range(epoch):\n","        for batch_idx, (data, target) in enumerate(trainset_loader):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = F.nll_loss(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            if iteration % log_interval == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n","                    100. * batch_idx / len(trainset_loader), loss.item()))\n","            # different from before: saving model checkpoints\n","            if iteration % save_interval == 0 and iteration > 0:\n","                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n","            iteration += 1\n","        test()\n","    \n","    # save the final model\n","    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URV-YhpD74w4","colab_type":"code","colab":{}},"source":["train_save(5, save_interval=500, log_interval=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"drlT8hsQlUwX","colab_type":"code","colab":{}},"source":["a = torch.load('/content/mnist-1000.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-fpEcnEl-O6","colab_type":"code","colab":{}},"source":["print(a.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1D9uvX7dlb77","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XMEPZxs762N","colab_type":"code","colab":{}},"source":["# create a new model\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","# load from the final checkpoint\n","load_checkpoint('mnist-4690.pth', model, optimizer)\n","# should give you the final model accuracy\n","test()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3QCD0yPCmj81","colab_type":"text"},"source":["# email: nqtran.sdh19@hcmut.edu.vn"]},{"cell_type":"markdown","metadata":{"id":"j634l5qk8JWu","colab_type":"text"},"source":["### Fine-tune mô hình"]},{"cell_type":"code","metadata":{"id":"oSR4DXlQ8IcD","colab_type":"code","colab":{}},"source":["# What's in a state dict?\n","print(model.state_dict().keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5YoHu5v8S9r","colab_type":"code","colab":{}},"source":["checkpoint = torch.load('mnist-4690.pth')\n","states_to_load = {}\n","for name, param in checkpoint['state_dict'].items():\n","    if name.startswith('conv'):\n","        # only load the conv layers\n","        states_to_load[name] = param\n","print(\"Number of parameter variables to load:\", len(states_to_load))\n","\n","# Construct a new state_dict in which the layers we want\n","# to import from the checkpoint is updated with the parameters\n","# from the checkpoint\n","model = Net().to(device)\n","model_state = model.state_dict()\n","print(\"Number of parameter variables in the model:\", len(model_state))\n","model_state.update(states_to_load)\n","        \n","model.load_state_dict(model_state)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukEq9azj8fUz","colab_type":"code","colab":{}},"source":["test() # without fine-tuning.\n","\n","train(1)  # training 1 epoch will get you to 93%!\n","# As a comparison, training from scratch for 1 epoch gets about ~80% test accuracy."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AGOJsnH8wRs","colab_type":"text"},"source":["Sử dụng mô hình pretrained"]},{"cell_type":"code","metadata":{"id":"7Losw1KC9AYw","colab_type":"code","colab":{}},"source":["class SmallNet(nn.Module):\n","    def __init__(self):\n","        super(SmallNet, self).__init__()\n","        # same conv layers\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        # fewer FC layers\n","        self.fc1 = nn.Linear(320, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = self.fc1(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = SmallNet().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"phjJwiKm9Evn","colab_type":"code","colab":{}},"source":["checkpoint = torch.load('mnist-4690.pth')\n","states_to_load = {}\n","for name, param in checkpoint['state_dict'].items():\n","    if name.startswith('conv'):\n","        states_to_load[name] = param\n","\n","# Construct a new state dict in which the layers we want\n","# to import from the checkpoint is update with the parameters\n","# from the checkpoint\n","model_state = model.state_dict()\n","model_state.update(states_to_load)\n","        \n","test()\n","\n","model.load_state_dict(model_state)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLzNjCIc9Hq7","colab_type":"code","colab":{}},"source":["train(1)  # training 1 epoch will get you to ~93%!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OyX7AFbx9WkW","colab_type":"text"},"source":["### Sử dụng nn.Sequential"]},{"cell_type":"code","metadata":{"id":"L9kxHAS89Kbk","colab_type":"code","colab":{}},"source":["class NetSeq(nn.Module):\n","    def __init__(self):\n","        super(NetSeq, self).__init__()\n","\n","        # conv layers: feature extractor\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(1, 10, kernel_size=5),\n","            nn.MaxPool2d(2),\n","            nn.ReLU(),\n","            nn.Conv2d(10, 20, kernel_size=5),\n","            nn.Dropout2d(),\n","            nn.MaxPool2d(2),\n","            nn.ReLU()\n","        )\n","        \n","        # fc layers: classifier\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(320, 50),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(50, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)\n","        x = x.view(-1, 320)\n","        x = self.fc_layers(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = NetSeq().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7DHgLBY9OB8","colab_type":"code","colab":{}},"source":["train(5)"],"execution_count":0,"outputs":[]}]}